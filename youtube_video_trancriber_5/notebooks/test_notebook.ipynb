{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\abit_mod1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() ##load all the nevironment variables\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "# from youtube_api import YoutubeDataApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are Yotube video summarizer. You will be taking the transcript text\n",
    "and summarizing the entire video and providing the important summary in points\n",
    "within 250 words. Please provide the summary of the text given here:  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transcript_details(video_id):\n",
    "    try:\n",
    "        transcript_text = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "        transcript = \"\"\n",
    "        for i in transcript_text:\n",
    "            transcript += \" \" + i[\"text\"]\n",
    "\n",
    "        return transcript\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the summary based on Prompt from Google Gemini Pro\n",
    "def generate_gemini_content(transcript_text,prompt):\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    response = model.generate_content(prompt + transcript_text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=os.getenv(\"YOUTUBE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_name = 'Channel Name'\n",
    "def get_channel_id(channel_name):\n",
    "    youtube = build('youtube', 'v3', developerKey=os.getenv(\"YOUTUBE_API_KEY\"))\n",
    "\n",
    "    channel_request = youtube.channels().list(\n",
    "        part='id',\n",
    "        forUsername=channel_name,\n",
    "        maxResults=5\n",
    "    )\n",
    "    channel_response = channel_request.execute()\n",
    "\n",
    "    # Get the channel ID\n",
    "    channel_id = channel_response['items'][0]['id']\n",
    "\n",
    "    return channel_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_response = get_channel_id('krishnaik06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'youtube#channelListResponse',\n",
       " 'etag': '1JNpVGLiUp94-zv5eFSAvMCOQDc',\n",
       " 'pageInfo': {'totalResults': 1, 'resultsPerPage': 5},\n",
       " 'items': [{'kind': 'youtube#channel',\n",
       "   'etag': 't3bRHzQgRuxznY6aGFQEtKLpDFU',\n",
       "   'id': 'UCQzSk4RM5JQ7UJJK5CWjPsQ'}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id=get_channel_id('MostlySane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UCQzSk4RM5JQ7UJJK5CWjPsQ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCvCyIiKSCA1fHKSCOKJyjXA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_recent_videos(channel_id):\n",
    "    youtube = build('youtube', 'v3', developerKey=os.getenv(\"YOUTUBE_API_KEY\"))\n",
    "\n",
    "    request = youtube.search().list(\n",
    "        \n",
    "        part=\"snippet\",\n",
    "        channelId=channel_id,\n",
    "        order=\"date\",               #  'searchSortUnspecified', 'date', 'rating', 'viewCount', 'relevance', 'title', 'videoCount'\n",
    "        type=\"video\",\n",
    "        maxResults=5\n",
    "    )\n",
    "\n",
    "    response = request.execute()\n",
    "\n",
    "    video_ids = [item['id']['videoId'] for item in response['items']]\n",
    "\n",
    "    video_titles = [item['snippet']['title'] for item in response['items']]\n",
    "\n",
    "\n",
    "    # return video_ids,video_titles\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_top_5_recent_videos('UCvCyIiKSCA1fHKSCOKJyjXA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'youtube#searchListResponse',\n",
       " 'etag': '74rA4V-cZEovQkJnJgqIUlmjsok',\n",
       " 'nextPageToken': 'CAUQAA',\n",
       " 'regionCode': 'IN',\n",
       " 'pageInfo': {'totalResults': 195061, 'resultsPerPage': 5},\n",
       " 'items': [{'kind': 'youtube#searchResult',\n",
       "   'etag': 'v3_sY8jCo1rtt2p1Jz3EcESdvHc',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 'hubXjZr31AQ'},\n",
       "   'snippet': {'publishedAt': '2024-04-05T06:02:42Z',\n",
       "    'channelId': 'UCvCyIiKSCA1fHKSCOKJyjXA',\n",
       "    'title': 'Itâ€™s working.',\n",
       "    'description': 'Click here to Subscribe :- http://bit.ly/PrajaktaKoli Click here to buy my merch - https://mostlysane.themerchbay.com/ Link To My ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/hubXjZr31AQ/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/hubXjZr31AQ/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/hubXjZr31AQ/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'MostlySane',\n",
       "    'liveBroadcastContent': 'none',\n",
       "    'publishTime': '2024-04-05T06:02:42Z'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': 'Fdv6N2FN5S051EwH90M4D9k_zks',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 'e4ea0b5erGU'},\n",
       "   'snippet': {'publishedAt': '2024-04-02T12:36:44Z',\n",
       "    'channelId': 'UCvCyIiKSCA1fHKSCOKJyjXA',\n",
       "    'title': 'I was looking for the one song that wonâ€™t go with this reel. I did well, I think.',\n",
       "    'description': 'Click here to Subscribe :- http://bit.ly/PrajaktaKoli Click here to buy my merch - https://mostlysane.themerchbay.com/ Link To My ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/e4ea0b5erGU/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/e4ea0b5erGU/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/e4ea0b5erGU/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'MostlySane',\n",
       "    'liveBroadcastContent': 'none',\n",
       "    'publishTime': '2024-04-02T12:36:44Z'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': 'Ve8BcmDFJqXagUekHXmFmsm4nAo',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 'MuKI97bOjjo'},\n",
       "   'snippet': {'publishedAt': '2024-03-26T14:30:07Z',\n",
       "    'channelId': 'UCvCyIiKSCA1fHKSCOKJyjXA',\n",
       "    'title': 'Cheers!..',\n",
       "    'description': 'Click here to Subscribe :- http://bit.ly/PrajaktaKoli Click here to buy my merch - https://mostlysane.themerchbay.com/ Link To My ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/MuKI97bOjjo/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/MuKI97bOjjo/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/MuKI97bOjjo/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'MostlySane',\n",
       "    'liveBroadcastContent': 'none',\n",
       "    'publishTime': '2024-03-26T14:30:07Z'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': '8UctZUinvNdrn1DZCXsv-IpSoks',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 'pB5lIFcdVSs'},\n",
       "   'snippet': {'publishedAt': '2024-03-26T12:45:21Z',\n",
       "    'channelId': 'UCvCyIiKSCA1fHKSCOKJyjXA',\n",
       "    'title': 'Round 2 ðŸ¥Š',\n",
       "    'description': 'Click here to Subscribe :- http://bit.ly/PrajaktaKoli Click here to buy my merch - https://mostlysane.themerchbay.com/ Link To My ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/pB5lIFcdVSs/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/pB5lIFcdVSs/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/pB5lIFcdVSs/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'MostlySane',\n",
       "    'liveBroadcastContent': 'none',\n",
       "    'publishTime': '2024-03-26T12:45:21Z'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': 'UhuSRjpi7hwz2nM2BnNIcRq2WP0',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 'hzN8An1a6-s'},\n",
       "   'snippet': {'publishedAt': '2024-01-29T09:27:53Z',\n",
       "    'channelId': 'UCvCyIiKSCA1fHKSCOKJyjXA',\n",
       "    'title': 'Always prepared.',\n",
       "    'description': 'Click here to Subscribe :- http://bit.ly/PrajaktaKoli Click here to buy my merch - https://mostlysane.themerchbay.com/ Link To My ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/hzN8An1a6-s/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/hzN8An1a6-s/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/hzN8An1a6-s/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'MostlySane',\n",
       "    'liveBroadcastContent': 'none',\n",
       "    'publishTime': '2024-01-29T09:27:53Z'}}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids,video_titles = get_top_5_recent_videos(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Testmovie2.avi',\n",
       " '7: Final part 1',\n",
       " '8:Final Part two',\n",
       " '6: Josh/Goat',\n",
       " '5: The Commons']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript0=extract_transcript_details(video_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript1 = extract_transcript_details(video_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript4 = extract_transcript_details(video_ids[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152032"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcript4*24+transcript1+transcript0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.796399751707014"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "152032/12888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=generate_gemini_content(transcript4*24+transcript1+transcript0,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Summary: Python Roadmap for Aspiring Experts**\\n\\n**Point 1: Determine Your Goal and Timeline**\\n\\n* Define your learning purpose (e.g., data science, web development)\\n* Set a realistic timeline (e.g., 3 months for data science)\\n\\n**Part 1: Python Syntax and Basic Operations**\\n\\n* Jupyter Notebook\\n* Basic arithmetic operations\\n* Variables, control and conditional structures (if/else)\\n* Loopings (for/while)\\n* User input, strings, integers, floats, type casting (2 days)\\n\\n**Part 2: Built-in Data Structures and Functions**\\n\\n* Python strings, lists, booleans, sets, dictionaries, tuples (3 days)\\n* Functions in Python: user-defined and built-in\\n* Exception handling\\n* Importing libraries\\n\\n**Part 3: Object-Oriented Programming (OOP)**\\n\\n* Classes, objects, methods\\n* Inheritance, polymorphism, encapsulation (4 days)\\n\\n**Part 4: Libraries for Python**\\n\\n* NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn\\n* Web development frameworks: Flask, Django (4 days)\\n\\n**Intermediate-Level Specialization**\\n\\n* Web Development: Flask, Django, React.js, Angular.js, Node.js\\n* Desktop Application Frameworks: PyQt, Kivy, Tkinker\\n* Machine Learning and Deep Learning: Scikit-learn, TensorFlow, Keras, PyTorch\\n\\n**Advanced-Level Expertise**\\n\\n* Frameworks for machine learning and deep learning\\n* Deployment in the cloud\\n\\n**Key Points to Remember**\\n\\n* Focus on your end goal\\n* Set realistic time frames\\n* Learn daily and always seek knowledge\\n* Use Google as your resource\\n* Don't be hard on yourself\\n* Don't compare yourself to others\\n* Remember that setbacks are part of learning\\n* Don't hesitate to ask for help\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" hello all my name is krishnaik and welcome to my YouTube channel so guys finally I'm going to start the seven days end-to-end machine learning project implementation with mlops and cicd pipelines I had announced this last month that I'm planning to do it and I had asked question that whether you want recorded videos or live session and many of you had actually demanded for the recorded videos so yes finally from tomorrow that is Sunday that is 5th March uh at 8 pm you will be getting the record\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9306\n",
      "30118\n",
      "279708\n",
      "360054\n",
      "4692\n"
     ]
    }
   ],
   "source": [
    "for video in video_ids:\n",
    "\n",
    "    transcript = extract_transcript_details(video)\n",
    "    print(len(transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_channel_id_from_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(response.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Perfect Roadmap To Become AI Engineers In 2024 With Free Videos And Materials',\n",
       " 'It Is Easy To Start But Difficult to ...',\n",
       " 'Groq-LPUâ„¢ Inference Engine Better Than OpenAI Chatgpt And Nvidia',\n",
       " 'AI vs ML vs DL vs Generative Ai',\n",
       " '3-Langchain Series-Production Grade Deployment LLM As API With Langchain And FastAPI']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item['snippet']['title'] for item in response['items']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kind': 'youtube#searchResult',\n",
       "  'etag': 'I1FIWX14CjJszoUSorHaC3xo71o',\n",
       "  'id': {'kind': 'youtube#video', 'videoId': 'bkhUjwJbP1k'},\n",
       "  'snippet': {'publishedAt': '2024-04-05T13:53:47Z',\n",
       "   'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig',\n",
       "   'title': 'Perfect Roadmap To Become AI Engineers In 2024 With Free Videos And Materials',\n",
       "   'description': 'Artificial intelligence (AI) is a branch of computer science that involves programming machines to think like human brains.',\n",
       "   'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/bkhUjwJbP1k/default.jpg',\n",
       "     'width': 120,\n",
       "     'height': 90},\n",
       "    'medium': {'url': 'https://i.ytimg.com/vi/bkhUjwJbP1k/mqdefault.jpg',\n",
       "     'width': 320,\n",
       "     'height': 180},\n",
       "    'high': {'url': 'https://i.ytimg.com/vi/bkhUjwJbP1k/hqdefault.jpg',\n",
       "     'width': 480,\n",
       "     'height': 360}},\n",
       "   'channelTitle': 'Krish Naik',\n",
       "   'liveBroadcastContent': 'none',\n",
       "   'publishTime': '2024-04-05T13:53:47Z'}},\n",
       " {'kind': 'youtube#searchResult',\n",
       "  'etag': 'cMucgA-o57gc61WHrINEn6wARnA',\n",
       "  'id': {'kind': 'youtube#video', 'videoId': 'WzV1eUiGv2M'},\n",
       "  'snippet': {'publishedAt': '2024-04-05T05:06:42Z',\n",
       "   'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig',\n",
       "   'title': 'It Is Easy To Start But Difficult to ...',\n",
       "   'description': 'Support me by joining membership so that I can upload these kind of videos ...',\n",
       "   'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/WzV1eUiGv2M/default.jpg',\n",
       "     'width': 120,\n",
       "     'height': 90},\n",
       "    'medium': {'url': 'https://i.ytimg.com/vi/WzV1eUiGv2M/mqdefault.jpg',\n",
       "     'width': 320,\n",
       "     'height': 180},\n",
       "    'high': {'url': 'https://i.ytimg.com/vi/WzV1eUiGv2M/hqdefault.jpg',\n",
       "     'width': 480,\n",
       "     'height': 360}},\n",
       "   'channelTitle': 'Krish Naik',\n",
       "   'liveBroadcastContent': 'none',\n",
       "   'publishTime': '2024-04-05T05:06:42Z'}},\n",
       " {'kind': 'youtube#searchResult',\n",
       "  'etag': '62FQs581B2ls0KYOpMuHtJtzvpA',\n",
       "  'id': {'kind': 'youtube#video', 'videoId': 'rHphpyf0i0I'},\n",
       "  'snippet': {'publishedAt': '2024-04-04T15:24:24Z',\n",
       "   'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig',\n",
       "   'title': 'Groq-LPUâ„¢ Inference Engine Better Than OpenAI Chatgpt And Nvidia',\n",
       "   'description': 'Groq is on a mission to set the standard for GenAI inference speed, helping real-time AI applications come to life today. An LPU ...',\n",
       "   'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/rHphpyf0i0I/default.jpg',\n",
       "     'width': 120,\n",
       "     'height': 90},\n",
       "    'medium': {'url': 'https://i.ytimg.com/vi/rHphpyf0i0I/mqdefault.jpg',\n",
       "     'width': 320,\n",
       "     'height': 180},\n",
       "    'high': {'url': 'https://i.ytimg.com/vi/rHphpyf0i0I/hqdefault.jpg',\n",
       "     'width': 480,\n",
       "     'height': 360}},\n",
       "   'channelTitle': 'Krish Naik',\n",
       "   'liveBroadcastContent': 'none',\n",
       "   'publishTime': '2024-04-04T15:24:24Z'}},\n",
       " {'kind': 'youtube#searchResult',\n",
       "  'etag': '7Tw8KkrUpTITDSu7wacQggQ-oUQ',\n",
       "  'id': {'kind': 'youtube#video', 'videoId': 'X7Zd4VyUgL0'},\n",
       "  'snippet': {'publishedAt': '2024-04-03T16:56:49Z',\n",
       "   'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig',\n",
       "   'title': 'AI vs ML vs DL vs Generative Ai',\n",
       "   'description': 'In this video we will discuss about AI vs ML vs DL vs Generative AI.Generative artificial intelligence is artificial intelligence capable ...',\n",
       "   'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/X7Zd4VyUgL0/default.jpg',\n",
       "     'width': 120,\n",
       "     'height': 90},\n",
       "    'medium': {'url': 'https://i.ytimg.com/vi/X7Zd4VyUgL0/mqdefault.jpg',\n",
       "     'width': 320,\n",
       "     'height': 180},\n",
       "    'high': {'url': 'https://i.ytimg.com/vi/X7Zd4VyUgL0/hqdefault.jpg',\n",
       "     'width': 480,\n",
       "     'height': 360}},\n",
       "   'channelTitle': 'Krish Naik',\n",
       "   'liveBroadcastContent': 'none',\n",
       "   'publishTime': '2024-04-03T16:56:49Z'}},\n",
       " {'kind': 'youtube#searchResult',\n",
       "  'etag': 'sdaW5jFc_tpD9xLBZHjgLyc9-MI',\n",
       "  'id': {'kind': 'youtube#video', 'videoId': 'XWB5DXP-DO8'},\n",
       "  'snippet': {'publishedAt': '2024-04-03T13:27:29Z',\n",
       "   'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig',\n",
       "   'title': '3-Langchain Series-Production Grade Deployment LLM As API With Langchain And FastAPI',\n",
       "   'description': 'github: https://github.com/krishnaik06/Updated-Langchain LangServe helps developers deploy LangChain runnables and chains ...',\n",
       "   'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/XWB5DXP-DO8/default.jpg',\n",
       "     'width': 120,\n",
       "     'height': 90},\n",
       "    'medium': {'url': 'https://i.ytimg.com/vi/XWB5DXP-DO8/mqdefault.jpg',\n",
       "     'width': 320,\n",
       "     'height': 180},\n",
       "    'high': {'url': 'https://i.ytimg.com/vi/XWB5DXP-DO8/hqdefault.jpg',\n",
       "     'width': 480,\n",
       "     'height': 360}},\n",
       "   'channelTitle': 'Krish Naik',\n",
       "   'liveBroadcastContent': 'none',\n",
       "   'publishTime': '2024-04-03T13:27:29Z'}}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube#searchListResponse\n",
      "r4yc6N3E5muh1TYC5ZVO3NCaWS0\n",
      "CAUQAA\n",
      "IN\n",
      "{'totalResults': 151217, 'resultsPerPage': 5}\n",
      "[{'kind': 'youtube#searchResult', 'etag': 'I1FIWX14CjJszoUSorHaC3xo71o', 'id': {'kind': 'youtube#video', 'videoId': 'bkhUjwJbP1k'}, 'snippet': {'publishedAt': '2024-04-05T13:53:47Z', 'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig', 'title': 'Perfect Roadmap To Become AI Engineers In 2024 With Free Videos And Materials', 'description': 'Artificial intelligence (AI) is a branch of computer science that involves programming machines to think like human brains.', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/bkhUjwJbP1k/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/bkhUjwJbP1k/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/bkhUjwJbP1k/hqdefault.jpg', 'width': 480, 'height': 360}}, 'channelTitle': 'Krish Naik', 'liveBroadcastContent': 'none', 'publishTime': '2024-04-05T13:53:47Z'}}, {'kind': 'youtube#searchResult', 'etag': 'cMucgA-o57gc61WHrINEn6wARnA', 'id': {'kind': 'youtube#video', 'videoId': 'WzV1eUiGv2M'}, 'snippet': {'publishedAt': '2024-04-05T05:06:42Z', 'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig', 'title': 'It Is Easy To Start But Difficult to ...', 'description': 'Support me by joining membership so that I can upload these kind of videos ...', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/WzV1eUiGv2M/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/WzV1eUiGv2M/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/WzV1eUiGv2M/hqdefault.jpg', 'width': 480, 'height': 360}}, 'channelTitle': 'Krish Naik', 'liveBroadcastContent': 'none', 'publishTime': '2024-04-05T05:06:42Z'}}, {'kind': 'youtube#searchResult', 'etag': '62FQs581B2ls0KYOpMuHtJtzvpA', 'id': {'kind': 'youtube#video', 'videoId': 'rHphpyf0i0I'}, 'snippet': {'publishedAt': '2024-04-04T15:24:24Z', 'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig', 'title': 'Groq-LPUâ„¢ Inference Engine Better Than OpenAI Chatgpt And Nvidia', 'description': 'Groq is on a mission to set the standard for GenAI inference speed, helping real-time AI applications come to life today. An LPU ...', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/rHphpyf0i0I/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/rHphpyf0i0I/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/rHphpyf0i0I/hqdefault.jpg', 'width': 480, 'height': 360}}, 'channelTitle': 'Krish Naik', 'liveBroadcastContent': 'none', 'publishTime': '2024-04-04T15:24:24Z'}}, {'kind': 'youtube#searchResult', 'etag': '7Tw8KkrUpTITDSu7wacQggQ-oUQ', 'id': {'kind': 'youtube#video', 'videoId': 'X7Zd4VyUgL0'}, 'snippet': {'publishedAt': '2024-04-03T16:56:49Z', 'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig', 'title': 'AI vs ML vs DL vs Generative Ai', 'description': 'In this video we will discuss about AI vs ML vs DL vs Generative AI.Generative artificial intelligence is artificial intelligence capable ...', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/X7Zd4VyUgL0/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/X7Zd4VyUgL0/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/X7Zd4VyUgL0/hqdefault.jpg', 'width': 480, 'height': 360}}, 'channelTitle': 'Krish Naik', 'liveBroadcastContent': 'none', 'publishTime': '2024-04-03T16:56:49Z'}}, {'kind': 'youtube#searchResult', 'etag': 'sdaW5jFc_tpD9xLBZHjgLyc9-MI', 'id': {'kind': 'youtube#video', 'videoId': 'XWB5DXP-DO8'}, 'snippet': {'publishedAt': '2024-04-03T13:27:29Z', 'channelId': 'UCNU_lfiiWBdtULKOw6X0Dig', 'title': '3-Langchain Series-Production Grade Deployment LLM As API With Langchain And FastAPI', 'description': 'github: https://github.com/krishnaik06/Updated-Langchain LangServe helps developers deploy LangChain runnables and chains ...', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/XWB5DXP-DO8/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/XWB5DXP-DO8/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/XWB5DXP-DO8/hqdefault.jpg', 'width': 480, 'height': 360}}, 'channelTitle': 'Krish Naik', 'liveBroadcastContent': 'none', 'publishTime': '2024-04-03T13:27:29Z'}}]\n"
     ]
    }
   ],
   "source": [
    "for key in list(response.keys()):\n",
    "    print(response[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bkhUjwJbP1k', 'WzV1eUiGv2M', 'rHphpyf0i0I', 'X7Zd4VyUgL0', 'XWB5DXP-DO8']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hello all my name is krishak and welcome to my YouTube channel so guys many many people were requesting quickly come up with the AI engineer road map um you know probably in every video from the day that I have actually uploaded a video about what does an AI engineer do you know and in the comments many people were saying CR please go ahead and upload this AI engineer road map complete AI engineer road map and uh yes I it took me some amount of time because uh I always provide you road map just not by saying you have to learn this or that I provide road map by providing you videos free videos complete course free videos along with that documentation link if I consider with respect to materials end to endend projects everything is basically included in all this kind of road maps whatever road maps that you probably see Let It Be ml Engineers data science data analyst I always make sure to do that you know now again uh in this specific road map you'll be completely seeing the AI Engineer Road map how you can actually become an AI Engineers uh along with this uh there are multiple things that is basically included over here uh don't worry about anything as such you don't even have to worry about materials handwritten notes also everything is available at one place you you will be able to find it everything in short right so let me quickly go ahead and share my screen as said uh in my previous video I've already told you what does an AI engineer do and I have explained you completely over here we had kept a target of th000 likes and 250 comments I think only 8 8 n likes is done and and somewhere around 66 comments is given please guys come on uh if you really want to motivate me a lot definitely do that let's make these videos quite engaging because this videos are super important videos right where many people have made career transition it is completely for free my aim is always to democratize AI education like everybody should have that access to all these kind of videos or materials whenever they really want to prepare okay but yes just try your best hit like and uh keep on seeing this entire road map okay now in this particular road map there are some amazing things that I have actually included uh uh you'll be seeing as we go ahead you know so in this particular road map first of all always remember whenever you start a road map you really need to understand what does this specific role actually do right in this case I have actually created with respect to AI Engineers so here is the video link the same video link what does an AI engineer do and you'll be able to find out everything about it you know explained it in probably 18 minutes and previously also I made a video but right now since generative AI is also becoming very much famous so everything is included over here second thing you have is AI engineer job description now always understand what does an AI engineer do first of all you really need to know and if you go ahead and click this you'll also be able to find out job description as I always said that most of the roles with respect to data scientist uh most of the roles with respect to data scientist AI Engineers uh with respect to machine learning engineers in India specifically in startup companies you know things are overlapped like roles and responsibilities are mostly overlapped but if you really want to understand what are the kind of roles and responsibilities actually a AI engineer do try to see for a bigger product based companies and then you probably go ahead and see the job description okay and this job description I've already explained what all things you really need to have skill sets and all everything as such right so here you'll be able to see terms like product management field Eng engering ux designer quality Engineers you have to build a strong relationship and this is the most important word that is called as collaborate okay so both these links are specifically given over here to start preparing for this AI engineering role first of all you definitely need to know a programming language okay now you may be thinking Krish is this the road map same like a data scientist no guys there are lot of additional things that I've actually put over here as I said many of the roles many of the skill sets will be inter as an intersection okay will be very much common but there will be some more additional skills which I will be mentioning over here so overall this entire road map is of 6 months so the first thing that you really need to know is programming language that is python again right now python is the best no doubt probably in the upcoming decade just go with Python programming language because there are multiple things that are coming in private with the help of Python programming language if you see Lang chin as a web frame as a framework to create llm application it has functionalities with respect to to python or JavaScript right so all the apis that you'll be seeing all the libraries that you'll be seeing only with the help of python or JavaScript you'll be able to do it so just understand the importance of python like many people are using it many people are using to build even gen AI powered apps okay now with respect to python I have playlist in both my English and Hindi channel uh here you'll be able to see all this entire playlist link you just need to go ahead and click it uh as I said this entire road map is for 6 months so it is always good that try to give somewhere around 3 to 4 hours daily if you're giving 3 to 4 hours daily no one can actually stop you okay so here is your entire playlist then what is the final goal outcome after completing this python playlist is basic to intermediate python with various knowledge of various data structures like numai pandas matplot LA and many more knowledge of Performing Eda feature engineering creating visualization charts using python at least make some python projects using Frameworks such as flask and deployment like web scrapping project so this in short actually helps you to create projects it helps you to understand about how we can specifically use Python programming language in the real world scenario okay and whenever new things in Python comes please go ahead and check it out uh it is always good idea with respect to that after learning python obviously we really need to learn about statistics statistics whether you are data scientist whether you are a data analyst whether you are a AI engineer statistics is must again with respect to statistics I think I have everything uploaded both in Hindi playlist and uh English English playlist I've also taken a live session I think this will be more than sufficient because from all the people who have already made successful career transition they have myself they have actually given me a feedback chis your statistics video will be more than sufficient to answer any question in the interview and this is from all the people who have already made transition so if you whether you're going for the interviews whether you're going for anything this many statistics video is more than sufficient the best thing about statistics videos is that I have explained both disc descriptive and inferential statistics and I have considered real world scenario and how we can use statistical Concepts over there so both with the help of theoretical knowledge and practical implementation it is given in this specific playlist okay along with that if you really want more right so I have put some links with respect to Khan Academy also so Khan Academy uh it have they have the portal all the four courses are also free over there so anything that is related to mathematics like linear algebra statistics or differential equation or integration you can probably learn it from here and I have given all the Three Links over here okay so coming to the next thing once you learn statistics Once You Learn Python now it is the time that you should know how to play with the data right so why we are learning this I'll tell you just in some time okay it'll completely make sense okay so here you have Eda live Eda detailed playlist then you have feature engineering Right Live both live and complete detailed uh feature engineering I completed over here what is the final goal and outcome come it is very much simple techniques to perform statistical analysis familiar with all Concepts which will be important for machine learning okay then coming to the databases once you probably completing this I think this is very much common with respect to machine learning Engineers data scientist on anyone you probably go okay databases obviously I always say that please go ahead with one SQL database and one no SQL database so here you have mongodb here you have MySQL here you have apachi Cassandra database okay so all these videos have also been uploaded I've also shown you how you can integrate with python code how you can actually go ahead and insert your data everything is basically mentioned all along with all my videos just imagine guys 1900 plus videos is not a joke all these videos are very meaningful videos trust me if you're referring just to the all this free content anybody can make a transition after you probably learned databases now it's the time for machine learning now see in machine learning you have supervised unsupervised machine learning I think uh uh with respect to the playlist that I've created both in my and Hindi channel uh it has garnered millions and millions of views okay probably millions and millions of views you can go ahead and check this playlist every every video has if I combine totally if I combine it is in millions or cores right I'll say okay so complete ml playlist in Hindi live ml playlist Hindi ml playlist both supervised unsupervised like what are the important machine learning algorithms like linear regression uh Ridge lasso elastic completely mathematical intuition along with the explan along with practical implementation everything is given over here not only that decision random Forest XG boost and then you have gradient boost all these things are covered similarly with respect to Hindi also I've actually covered this unsupervised machine learning like C in clustering highle mean DB scan everything along with mathematical intuition and practical implementation everything is covered over here I don't think so you really need to go ahead and uh probably see other resources this will be more than sufficient then coming to the Deep Lear playlist as I said machine learning deep learning I have completed one year back itself all the videos so here you'll be also able to see the specific deep learning playlist here I focused ONN CNN RNN variants of RNN like Transformers Gru then you have encoder decoder then you have lstm RNN and uh you also have techniques like uh uh self attention attention is all you need then you have Transformer then you have burn all these videos have also been uploaded with respect to deep learning and that is where NLB playlist is also coming NLP both in machine learning and deep learning I've covered both of them now why all these things I learned understand one thing because this techniques this whatever uh techniques or whatever terms I've used over here these are mostly used in the life cycle of a data science project whenever we consider a life cycle of a data science project we basically start from data injection to feature engineering data transformation then model training then model deployment after that monitoring will specifically happen if I consider till deep learning you can can actually do the uh Eda data transformation model training part till here right Which models to specifically use how to check the model how to check the performance metrics everything is done till here right till NLB playlist then when we come to the deployments and here is what machine learning engineer roles also comes into existence okay as I said AI Engineers will overlap in machine learning also machine learning Engineers also data scientist also so important Frameworks for production deployment like flask you have flask oneshot video gradio framework Bento ml flow and dhub and if you really want to focus on apis then fast API is also there so all this kind of links and videos also I've actually put up with respect to there if you search for Flash detail playlist just search with that name then you'll be able to understand it now is the most important thing once you learn all these Frameworks now you know how to probably do the deployment in the form of apis or how to integrate with any software application that it be a web application or Android right and that is where your mlops will probably start now this mlops the cycle that you specifically see in data science if you if you know about software engineering life cycle or software development life cycle we right now in the industry we use a process which is called as agile process and similarly in data science or uh if I probably consider AI module life cycle software development life cycle there also we can specifically use agile process because agile process actually helps you to integrate the client feedback regularly because all the the stories are divided into Sprints now to understand how the stories are divided into Sprints what is QA environment what is Dev environment what is U at what is production all these environments also you should really need to understand because in mlops we also create cicd pipeline just to give you an idea if you really want to understand about software development life cycle and data science project development life cycle I've created one amazing video 18 Minutes video here you'll be able to understand all these things what is Sprints how when a project is basically started who is the first person that is involved like business analyst product manager when they do the requirement Gathering how do they divide all the stories into Sprints how the Team Planning is done how many developers we really need to consider you know based on that how many Sprints we need to cover in uh in based on time um how many weeks specifically one Sprint goes ahead with all these things you really need to understand because this is the bigger picture as a data scientist you'll just focus on that same thing right feature engineering Eda data transformation model training right and once you create the model that is done but here as an AI engineer you really need to understand about the software development life cycle also and that is the reason I've created a video over here right so if you click this video everything I've explained completely from scratch okay now it is important you also need to know about machine learning operations because this is also must okay because at the end of the day once you create your model you need to do the deployment you're using a framework then you have to probably create GitHub action cicd pipeline Circle CI you can also use Circle CI to do the deployment Q flow MLF flow this actually manages the entire life cycle of a data science project deployment techniques you should know in AWS Azure gcp kubernetes what is evidently AI there are lot of Open Source monitoring tools right graph is also there airflow to even to manage event scheduler Bento ml AWS Sage maker how you can actually use it DVC data versioning control Dockers there's so many things that I have already created in the form of videos I'm not saying saying that you should know at least each and everything at least GitHub action cicd pipeline ml flow if you know evidently AI to just understand that how the model is monitoring getting monitored AWS cica DVC Docker Docker is a must if you pick up all the specific things then you will be able to understand how and end to end data science or AI project is specifically done in all my AI projects one amazing thing in my channel if you see all the AI projects I've always made sure that I have developed AI as a application itself otherwise as a API which can probably integrated in any kind of application so considering that once you probably complete this here are all the projects that I have actually created for you and the best thing about this particular project is that it includes machine learning project deep learning projects natural language processing projects uh computer vision projects mlops projects mlflow projects so it in includes almost everything not only that openi project kidney classification computer vision project all the things it's it is basically included and this is what is the variety that I actually given you right once you get this specific variety I think no one can stop you in doing or cracking any job interviews right now as you all know generative AI is also becoming very popular so that is the reason I've also created road map to generative Ai and along with this all the playlist I created more than 150 videos right updated Lang chain playlist um now this is important see as an AI engineer right uh this thing you really need to understand whether AI engineer see once that entire application is deployed right let's say it is in it is given in the form of API now that API needs to be consumed from web application from Android app from desktop app multiple places right similarly now since generative AI is very becoming very famous right now we have pre-trained models we have Foundation models now to solve our custom use cases we really need to fine tune all these models all this fine-tuning process will also be done by an AI engineer and that is the reason here you can see that I've created updated player langin playlist fine-tuning techniques in llm I've explained the entire thing like Laura CLA quantisation what it is one bit llm what exactly it is everything is basically explained in this particular playlist then you have AWS Bedrock then you have llama index playlist Google gini playlist with project Slangin playl playlist which was the older one there was some other updates which I'm probably uploading in this specific playlist itself right so this in turns covers generative AI also and here you can see how much content I actually given you guys I think uh this much content if you are again I'm telling you unless you don't devote time 3 to 4 hours trust me you won't be able to crack it but yes if you devote it trust me you have a lot of things to explain now this is also important which I have actually mentioned specially mentioned good to have skills you really need to have some knowledge with respect to Big Data engineering or Cloud Engineering also why I'm saying you is that because in my previous project in my previous company uh that is Panasonic when I was working I had to communicate with the data engineering team iot team I had to communicate with the cloud team and at why I was actually doing that because we had created a model completely from scratch how to fine-tune that model when how much new data is basically going to come from the iot itself how we are going to integrate with respect to uh see from the cloud also we'll be getting some different data from iot devices also we'll be getting data Big Data team how they can actually combine it in the form of Pipeline and store it in some kind of database and after that how can I probably accommodate those particular data and find you in my model so all these needs to have a discussion so that is the reason why I'm saying that you really need to have a good knowledge of Big Data engineering and Cloud engineering I'm not saying become an expert but at least what things are there what is there in the ecosystem you really need to understand okay so as usual once you probably complete this then are the internships you can apply in internships in this particular link along with that these are all my other links which you can also subscribe and support by taking amazing uh support support by joining my channel as a membership uh it will definitely help me to create more this kind of videos but if I say this guys uh this is really amazing thing that I've done in the past 5 years you know people who are having issues with respect to money and all and here I've given so many different free things so that you can always learn at any point of time so I hope you like this particular video this was it for my side I'll see you all in the next video have a great day thank you one all take care bye-bye\n",
      " hello all my name is krishak and welcome to my YouTube channel so guys just a small raw video for everyone of you out there uh I usually keep a habit to have a conversation with various people who are preparing for different roles in the IT industry uh and this conversation that I specifically have where I try to understand their problem I I try to understand how they have overcome various situation and probably made transition into the industries uh what all path they have specifically taken to achieve this you know and this kind of conversations helped me to understand what is currently happening in the industry and uh since I really give a lot of career advice so this conversation actually helped me to also provide advice to the others what steps to specifically take now I hope uh you have seen the title of the video the title of the video is that it is easy to start start something right but difficult to you know and we can keep any number of blanks right difficult to complete stay focused stay disciplined probably focused on achieving that specific goal it can be multiple things uh this video I really want to share one conversation that I had with one of the person who is right now working uh as an intern in one of the company as a data analyst you know and if I see the story if I probably if I if I see the entire conversation that had happened and if I see that entire transition that the person has actually made it is quite amazing to think and the title that I have actually written right it fits perfectly for this you know so the person had completed uh his engineering somewhere in 2022 okay and uh after completing his engineering obviously he was not able to get the job because uh uh he was coming from a third Tire College itself and there was no placement in the College itself right then after that what happened is that he he again prepared for the data analytics industry itself for the next 6 months uh he started looking for jobs okay and uh he gave couple of interviews but he was not able to crack them and obviously in every Point everybody's point of life you know there will be one situation when people will start thinking hey if this is not working out I should probably try this and that is the reason he started working for this uh he started preparing for the government services exams also then one and a half year you know he devoted in this and over there also he what what he like he gave his 100% with respect to the preparation you know and there also he was not able to be successful and obviously when parents when our parents right when they see hey after probably completing your education you have not done anything for 2 years right and that is really you're missing your t two years then the parents suggested hey do one thing you know prepare for both the things right obviously your career Gap should not increase wherein you really need to focus on getting a job yes whatever field you're really interested in and he said that hey I want to really go into the data analytics industry so he started preparing for data analyst and he also started preparing for this Services government services exams now that there was a time when he when he started preparing right for the straight 6 months he devoted his time completely for the data analytics industry since he was preparing for the data analyst part over there right now I now currently he's working as an intern okay he was able to make a successful career transition so I I specifically asked him okay so in this point of time when he had this one and a half to two years Gap right two years Gap specifically what all path he thought of making this specific transition and preparing for the data analytics industry he simply said sir Krish I have seen your videos you have shown so many number of successful career transition and this successful career transition stories help me to understand or learn many things because I have also uploaded successful career transition from where people have made successful career transition for having a career Gap and right now they are having a full-time job and trust me guys history teaches you a lot of things right history basically means what people who have already achieved so that is what we basically see from from a successful career transition stories we get to learn a lot of things what to do what not to do right so when you get this kind of learnings it becomes easy and it helps us to understand hey I have to specifically take this specific path so the person what he did is that when I had a conversation with him he said Krish I just Tred to make my entire road mapap with multiple paths right who's already made this kind of transition for having a career graph into this indust what all specific path he or she took it right so all the path he basically took it and then which path to basically follow which was which path was feasible for him he started working on those specific path itself and trust me uh he he actually demonstrated he was saying me hey Kish I went with eight to nine different parts the first part was that just focus on internship so that I can actually reduce my career Gap second part was that I will try to find out the differenti skill right now which is not available in the market I'll try to focus on that along with the skills that I am working in so that my recruiter will specifically get impressed third part is that I'll try to create some amazing end to end projects so those projects will be I'll be able to use in my resume and explain to the people explain to the interviewer why I came up with this specific projects Right One path can be open source contribution I'll try to contribute in such a way that and I'll keep on sharing the knowledge in my LinkedIn because through this way I may get some kind of reference refer right so I'm just giving some of the examples the person may have also taken some other part right there were eight to nine Parts over them now because of this planning you are now focused you know where you really want to go how you want to really achieve it and I feel everybody should have this kind of strategy while preparing for things and that is what I feel many people are missing it out you know people are not preparing with respect to that if you have that kind of strategy trust me it will definitely work out and what has happened after this after you prepared this one I the person has said in the first interview he was able to crack that particular internship even though he had a career Gap he had reasons for everything he told why I had a career Gap right he told how did he fix that career Gap how he's now fixing that career Gap everything and then what was his preparation of plan how did he achieve it everything step by step he did now this is where you really need to understand once you have set up your goal right as I said it's not like he did not he just started a data he just started to prepare for data analyst um you know just recently or 6 months back or 7 months back when he finished his college then also he started preparing but in Middle he left it because there was a mind change over there right so it is very easy to start something but very difficult to stay focused disciplined stay in that part so that they will be ACH able to achieve the goal right you what you really need to do is that make sure that you prepare in that specific way if I want to really achieve it I need to be disciplined in that specific manner I need to follow a path I need to prepare that specific path and once you able to do this once you're able to do the specific planning trust me you will be able to crack anything in your life as I said guys this is a raw video for everyone as you're starting your date this video will be definitely helpful out there and you will be able to do really amazing things in your life we are human beings and we are born to solve problems we are born to Sol not only problems but we are also born to find out a way to achieve anything in our life and that is what the research that is currently happening it is happening based on that we we trying to solve a new problem each and every day so come with a conclusion come with a thinking that anything is possible in this world you just need to work on that you need to come up with a plan that's it so this was it for my side I hope you like this particular video I'll see you in the next video have a great day thank you one all take care bye-bye\n",
      " hello all my name is krishak and welcome to my YouTube channel so guys um now I hope many of you are working or preparing to go into the field of generative AI I hope you have seen a lot of different kind of llm models uh like open AI chat gp4 turbo then you have llm models from Google like Google gini pro then you have also open source models like Lama 2 uh you have mistol you have cloudy 3 from anthropic right so many different different models are there both paid and open source right and all these companies will be in a fierce Rat Race competition who will probably try to create the best model you know and uh they will keep on publishing their news hey we have built this this is the performance metrix we are able to achieve this specific accuracy and one day AGI will definitely be coming up right and that is already in the process but I really want to ask you one question that which compan is going to win whether Opia is going to win or Google is going to win or meta is going to win or anthropic is going to win right everybody's in a fierce competition okay like tomorrow if openi comes up with something someone will come up with some more thing right so this competition is going to go ahead right but if I really want to talk about like which compan is going to win right the company which develops the most efficient inferencing engine will be the winner why because understand right now there are so many different kind of paid and open source llm models which can solve almost 80 to 90% of the tasks that are available in this specific World related to llms like with respect to Text data like creation of chat Bots and all right even code assistant everything this kind of use cases can be solved right but still what I feel the main challenging is with respect to the inferencing right now if you also try to go ahead and uh use some open source model try to run it in your local or try to run it in any Cloud to you definitely wait for the response for some number of seconds right and this is the major Challenge and right now now there are many companies who are also coming up with this amazing inferencing engine to make it more efficient and you get the response very much quickly and today in this particular video I'm going to talk about an amazing uh inferencing engine which is called as grock and uh it's not Twitter grock so that is gr but this grock is something called as gr oq a very important video guys for you all um I've already explored this I've also created a project the project will probably come in the uh next video but I will run one of the project over here and show you that how efficient it is and how it is able to probably provide you the ref uh the response itself now what is this Gro first of all we'll understand why Gro grock is a in on a mission to set the standard for Gen inferencing speed helping realtime a AI application come to life today now what does this basically mean let me go ahead and I have opened chat GPT over here okay and I've asked a question provide me a thousand words essay on what exactly is generative AI okay so this is one of the request that I'm making the same request I'm making it over here and understand Gro is basically using all the open source models like GMA 7B Lama 2 Mistral 8 into 7B and all right so first of all I will go ahead and hit for this chart GPT 4 and you'll be able to see that we will be getting the response the response is Right very very slow if I probably consider Char gb4 okay now the same response if I go ahead and hit it over here you will be able to see how quickly just imagine 857 tokens per second right and just in a time span of 2.71 seconds you are able to find out or you're able to get the entire response whereas in GPT chat GPT 4 you'll be able to see that it is a little bit slow right okay let's consider I'll I'll go ahead and use GPT 3.5 okay and I will go ahead and and uh use the same thing okay and let's see what kind of response I will quickly able to get or not and gbd 3.5 is a little bit fast so over here definitely we can see that grock is able to give me a quick response right if I go ahead and modify and try to say oh I want it for a professional reason right so here also you can see the token per second is 85736 I definitely don't think so your chat GPT 3.5 is giving in that spe specific way and this is what is basically called as inferencing how quickly you able to get the response just imagine n to ,000 words 1.59 seconds right if I go ahead and write some other thing right let's say provide me some python code to to to to to swap two numbers now just see this whether we'll be able to get it quickly or not see so fast right so fast with respect to all the tokens and tokens per second is 849.5 so definitely it is beating now how this is possible and that is where you really need to know about Gro what exactly is Gro this is not gr key gr K gr K grock is something different this is Twitter grock right Twitter has recently open source and now it is available for the premium user where you can create an API and do it right but let's talk about is Gro grock is on a mission to set the standards for Gen inference speed helping real time a application come to life today how it is able to do it it is because of this lpu inferencing engine right with lpu standing from L large uh language processing unit is a new type of end to-end processing unit system that provides faster inferences for computationally intensive application with SQL component to them such as AI large language applications now this is very very much important guys tomorrow if you're using it if you're directly using this specific API right trust me most of the use cases will be solved and the response time will be very very less right and in the future it is said that it is going to replace GPU GPU can be specifically used for training right but now lpu is able to do it much more better right so lpu designed to overcome two llm bottle networks compute density and memory bandwidth the lpu has a greater compute capacity than a GPU and a CPU in regards to llm right this reduce the the amount of time per word calculated allowing sequences of text to be generated much faster so definitely you can see that it is much more faster than the GPU itself if you probably go ahead and see there are lot of Articles like how inferencing is basically done if I go ahead and click one of the article over here right Gro lpu inferencing engine leads in First Independent llm Benchmark and now if I talk about token generation throughput see this is with respect to the all the models that we have like perlex City Amazon Bedrock fireworks Microsoft Azure with respect to number of lat uh with latency with group put tokens like number of tokens per second and here you can see Gro is able to go ahead till 240 tokens per second here Max to Max 100 tokens were there right and this is what is the major difference right grock can run several internal benchmarks reaching 300 tokens per second consistently right and this is all because of the technology that is called as npu reference now if you really want to know about what is lpu reference and how does it work you can probably read this particular article and I was I was also searching for a algorithm or research paper so this one research paper I specifically found it down algorithm and hardware for efficient processing of logic based neural network right and here you could get an understanding like how amazing grock is right now why Gro over here you have understood because of the lpu part that we specifically have and I think it is going to replace the gpus now as a person who is learning generative AI you just should not learn about LM models or how to create an application the main thing that you should really learn also is about how quickly you're able to inferencing this right so if I talk about more things over here so here you'll be able to see that I will also be able to see the price so here you can also get the API from it I will show you one application which I have already run it and uh you'll be able to see it the price you can see over here 300 tokens per second only7 right price per 1 million token 750 token1 480 token per second 27 by with the help of mral different different models are specifically there over here right so Gro has demonstrated 15 times faster llm inference performance and artificial intelligence compared to this okay so this definitely shows that there is a huge scope over here with respect to this inferencing engine and I think it can really become a fierce competitor for open Ai and obviously I don't know like whether it may harm Nvidia also with respect to this because if they are able to create this inferencing engine trust me with this inferencing engine they'll also see that how they can train the models how they can train the llm models also now just to give you an idea I had also developed an application over here let's run this okay so this is the entire code that I have written you definitely require an API key if you if you reach let's say that I'll keep a target for this particular video till tomorrow if you reach th000 likes I will try to upload this project end to end project completely and uh you can also see out this project project I will explain you everything and this is completely with the help of Open Source model now if I'm running this uh let me just go ahead and write stream late run app.py now here you'll be able to see how quick it quick it is you know so here uh let's run this application okay and uh it'll take some amount of time since I'm actually creating some Vector Tings from a website like attention is all you need right and this I've just taken the entire web page and I have probably done the indexing over here okay so uh for some amount of time it will take and once the indexing is done my website will be ready and then I can probably ask any kind of questions over here okay one more very important thing is that you really need to see all these articles and how things are basically getting developed and this is important for any person who are specifically working in the field of generative AI because inferencing is the most important thing now your work is done so let's go ahead and ask I'll ask a question can you summarize about so this is a Q&A chat chat Q&A right I've probably taken a website and from that website all the content has been indexed now I'm just going to ask a question with the help of Gro right can you summarize about attention attention is all you need let's press enter I'll also show you how much time it is probably taking up okay see how fast it is and it is also giving you the result with respect to document similarity search now if I go to my page back again1 seconds oh my God this is amazing okay just amazing and just imagine I've developed this entire application I'm also doing it with Vector databases and multiple things over here and the result is fabulous okay amazingly fabulous so I hope uh you like this particular video if you want this complete end to endend project again I have planned this project don't worry even though you don't make it, likes but it is just to give me that thrust so that I quickly upload this kind of videos for you all so I hope you like this particular video this was it for my side I'll see you all in the next video have a great Daye thank you one all take care bye-bye\n",
      " hello all my name is Kush naak and welcome to my YouTube channel so guys three to four years back you know I had created a video uh to make you understand the differences between AI versus ml versus DL versus data science and uh till now probably that is the video and that was a 9 Minutes video where I clearly differentiated between all these terms right specifically that you see over here and right now that is probably the most highest views video in my channel uh now as you know from past two years like from 2022 end until now right generative AI is really the Talk of the Town you know and uh with respect to generative AI if I talk about large language models open source large language models open AI doing s such an amazing word now cloudy 3 is also there to compete open aai you know and Amazon is definitely supporting them so you should know right what exactly is generative AI how is it different from all these terms or what is ex difference between AI versus ml versus DL versus generative AI so I'll make you understand in this specific video probably I'll try to make this video from somewhere between 15 to 20 minutes um I'll be including all simplistic terms very easy definition so that you'll be able to understand it because once you have that Clarity right uh at the end of the day right you really want to probably become an AI engineer you know which uses all these Technologies to create that AI apps so uh let's go ahead and let's understand this thing okay so as usual when I probably start the session you know let us consider the entire universe and uh in this field of universe I would definitely like to call this as AI okay now what is AI simple artificial intelligence the main aim is to build applications that can perform that can perform its own task without human intervention now this is the most important definition right without human intervention so it'll be able to perform its entire task without human intervention so let me just talk about it some of the examples As We Know uh Netflix right it has a amazing AI recommendation system recommendation system which recommends movies right now here human intervention is not required to probably provide you some kind of recommendation whatever things you using you're browsing the movies whatever movies you are specifically seeing you know at that point of time this AI model is actually helping you to provide you good recommendations so that you can stay for a longer period of time self-driving car is another example okay okay so self-driving car is another example right self-driving car now it is able to probably drive itself you know whenever the Turning is coming everything it is able to do see at the end of the day whichever field you specifically work right uh if I talk about AI Engineers this is very much important if I talk about AI engineers at the end of the day at the end of the day you are actually creating an AI product right and this product may be integrated with the software product itself right if I say Netflix it is a streaming platform movie streaming platform and if I talk about AI Engineers you know they are trying to integrate some amazing models you know which involves fine tuning which involves multiple things so that you integrate in such a way that it is quite scalable the machine learning engineer task will also come right so at the end of the day we are specifically creating an AI product and that product is getting seamlessly integrated with some uh you can probably say web app or Android app or mobile app or Edge devices something as such so I hope you got an idea with respect to AI so it is mostly about building applications that can perform its own tasks without human intervention now let's talk about machine learning now whenever I talk about machine learning machine learning is a subset of AI so this is basically machine learning it is a subset of AI and the main aim of machine learning is to provide you stats tools to perform to perform various tasks such as statistical analysis statistical analysis visualization visualization prediction and forecasting right so these are some of the examples that I've have just written it over here but at the end of the day what is machine learning it provides a lot of stats tools to proberbly perform the complete life cycle of a data science project that is specifically required uh in every life cycle from data inje to probably data transformation feature engineering you will be required some of the other concepts with respect to ml techniques where this is a very important term specifically if I say about that is nothing but stats tools okay so machine learning is a subset of AI right and here it is providing the stats tools to perform all this task and this task is usually performed on what on data now why we do this why we do this so that so that we understand about the data we understand about the data right so that a data will be meaningful it will be able to convey some information to you right so that is where machine learning basically comes into existence now coming to the next part that is nothing but deep learning so if I talk about deep learning again deep learning is a subset of machine learning and if I talk about deep learning from 1950s it's not like deep learning has become just famous right now yes it has become famous right now because of amazing things like gpus technological advancement open source libraries and many more things but this this entire deep learning was built to mimic human brain right human brain we wanted we wanted AI or we wanted machines to perform like how we human beings used to perform right how we human being used to learn so that is the reason as I said mimicking human brain and that is where we have something called as multi-layered neural networks right multi-layered neural networks so I hope you got a clear idea about this and here whenever I talk about deep learning there are three important things that we specifically learn right please understand this because after this only we'll be able to understand about generative AI so with respect to deep learning the three important things that we specifically learn right a Ann right CNN and then we basically say RNN and its variants right and this is where when I say RNN and its variant CNN and object detection CNN object detection is completely for computer vision purpose right so if I talk about task over here specifically you use computer vision over here you specifically use for what kind of use cases for textt related use cases right text related use cases right or you can also use it for time series use cases because that is how RNN and its variants are designed Right Time series use cases so Ann is definitely like how machine learning is basically trained similarly you can train machine learning problem statement with the help of a&n also right so overall most of the things that we specifically learn in deep learning are based on these three things okay when I say CNN object detection there are techniques like rcnn many more things and all right similarly RNN you have RNN LTM RNN Gru then you have encoder decoder attention is all you need then you have Transformers and birds right so I hope everybody has learned from my playlist till here everything has been explained along with theoretical intuition and practical intuition Transformer and B are something very Advanced and and from here only we will be deriving the next thing that is nothing but generative AI okay because this is the backbone used in most of the llm models in generative AI Transformers and birds okay so deep learning is mostly about this specific thing at the end of the day we are trying to mimic the human brain we are trying to understand how human beings specifically learn we also learn in the same way now coming to the next one that is nothing but generative AI obviously generative AI is a subset of deep learning again and here Advanced things okay so I will specifically talk about two types of model that we use in data science Industry models or two types of model training we specifically say right one is the discriminative uh if I if I just want to say it is that it's that's mostly like discriminative and generative models okay so if I talk about deep learning models they are mostly of two types okay this is one and this is the other one okay here you have something called as discriminative models here you have something called as generative models now you should understand whenever I talk about generative AI you should understand one very important thing generative AI is more about generating content okay so these are specific models which will help you to generate new content okay based on whatever content it has already been trained on okay if I talk about discriminative AI it is mostly about task like classification classification prediction all this regression prediction so all this tasks you can basically do in short over here your data set that you have right these are this entire discriminative models are trained on labeled data set you have to really understand this okay label data set similarly in the case of generative AI if I really want to understand about the task it is nothing but it generates new data trained on huge data set okay if I really want to make you understand right in a simple way if I just take okay I I am a person what I've done is that I have probably learned or read 100 books on cats right so I have been trained on this many number of books huge amount of data right now what I being a person if anybody ask me any questions with respect to cats I will be able to answer all the questions in my own way right and obviously the answers will be accurate because I've already read 100 books on the cat so similarly if I talk with respect to generative AI there are two types of models that we specifically learn one is large language models large image models large language model is with respect to Text data large image model is specifically with respect to images and videos so here if a text is given you can convert that into an image if a text if a text is given you can convert that into videos here large language mod if a text is given it will be able to provide some response in terms of text right and if I talk about all the various categories of LM models just in some time I'll be explaining you that also okay so generative AI in short what it is basically doing is that here we have models that is already trained in huge amount of data and the task of that specific models are based on any input it will generate a new data itself okay now to make you understand more about llm models right so if I talk about more llm models right obviously you know companies like open AI you know companies like meta Google anthropic right and every body's race in in the race right to generate the best llm model so this mod this this companies are already doing really really well anthropic basically comes up with a model which is called as cloudy 3 right right now it is being a fierce competitor of open a GPD 4 right gbd4 then you have in meta you have open source models like Lama 2 Google I hope everybody has heard about gini right in Google an open source model has also come which is called as Gemma right now what are all all these specific models these models are nothing but these are specifically called as Foundation models okay these Foundation models are also called as pre-trained models why we say it as pre-trained models because these are trained in huge amount of data the entire internet data huge data it has been trained in huge data the entire internet data right it may be code it may be multiple things and all right now we can use the specific model for domain specific use cases also domain specific use cases also and that is where a concept something called as fine tuning is used right and I have already created a playlist about fine tuning also I've explained Concepts like clora Laura how you can basically do the fine tuning how you can do it with uh open source models and many more things right the fierce competition right now is basically to get the best foundation model right and right now gp4 gp4 turbo soon GPT 5 is also going to come right if I talk about open source model Lama 3 is there in the pipeline right cloudy has just recently launched cloudy 3 gini is also coming up with German Pro more variants it is basically coming up so the main race if I probably talk about is to create the best foundation model later on many companies will be you able to use this Foundation model in the form of pre-train models or it will also they will also be able to fine tune with some own custom data set right to solve their use cases so this was the entire idea about generative AI again uh this is the video that I really needed to upload uh early but yes many people were waiting requesting for this specific video so I made you understand this entire thing by writing in front of you so for more details with respect to generative AI Lang chain now if I talk about Lang chain it is a framework right Lang chain is a framework which will be able to work with all the specific models at the end of the day we will be able to generate RG application ra application retrieval argumentation query uh and along with that we'll also be able to develop some amazing chat Bots that is the main reason right we why llm becoming very famous because of the chances of getting automated right we will be able to automate the entire chatbot response things with respect to it not only that it has a use scope in multiple sectors also with respect to various use cases uh this is with mostly about L models L models with respect to large image models stability uh stability AI is a company which is specifically working in this specific thing right so I hope you like this particular video for more videos related to Lang chain generative AI llm models you can follow my other playlist of Lang chain open Ai and all where you'll be able to see lot of end to-end projects so I hope you like this particular video I will see you all in the next video have a great day thank you and all take care bye-bye\n",
      " hello guys so we are going to continue the langin series already in our previous video we have already seen how to create chatbots with the help of both openai API and open source llm models like llama 2 we have also seen what is the use of AMA how you can run all these open source model locally in your system and uh along with this we also created multiple end to-end projects using both of them now what we are going to do in this specific video one more step which is very much important for our product production Gade deployment that is creating apis you know for all this kind of llm models we will be able to create AP and uh through this you will also be able to do the deployment in a very efficient manner now how we are going to create this specific apis there is a very important component uh which is called as Lang serve in Lang chain we're going to use that along with this we are going to use fast API um and not only that we'll also create a sag Swagger UI which is already provided by langin uh the Lang serve library that we are specifically going to use now it is important guys you know this specific step because tomorrow if you are also developing any application you obviously want to do the deployment for that particular application so creating uh the entire API for this application will be the first task that will be required so uh yes let's continue let's go ahead and uh discuss this entire thing first of all how we are going to go ahead first of all I'm going to show show you the theoretical intuition how we going to develop it and then we will start the coding part so let me quickly go ahead and share my screen what we are actually going to do over here over here I se you have seen that I've written apis for deployment okay so if I consider this diagram this is the most simplistic diagram that I could draw okay now let's consider see um the at the end of the day in companies right uh there will be different different uh applications this applications are obviously created by software Engineers right it can be a mobile app it can be a desktop app web app and all now for this particular app if I want to integrate uh any foundation model or any fine-tuned foundation model like llms and all um so what I really need to do is that I need to integrate this with the form of apis at the end of the day see what we are going to do over here this side is my llm models itself right it can be a finetuned llm models it can be a foundation model I want to use those functionality along with my web app or mobile app so what we are doing is over here is that we will create this specific apis now this apis will be having routes okay routes and this routes will be responsible whether we have to probably interact with open aai or whether we have to interact with other llm model like Cloud 3 cloudy 3 or llama 2 open source model so any number of llm models whether it is open source or uh whether it is uh paid API models specifically for llm we can definitely use it now this is what we are going to do in this video we will create this separately we will create this separately and at the end of the day I'll also give you an option through routes how you can integrate with multiple llm models right so I hope you have got an idea with respect to this and any number of llm models it may probably come you can probably integrate it at the end of the day whichever model is suitable for you you can use for different different functionality and the reason why I'm making this video understand one thing guys because in llms also you have different performance metrics some model is very good at some performance metrics over there like mlu other other metrics are definitely there so this is an option where we can use multiple llm models now what we are going to do quickly I will go ahead and open my code document so in in my previous video already you have seen I had actually developed till here right I have basically if you see over here we have created this first folder that is sharebot and inside the Shad bot we have created app.py then local Lama py right we with this did this entire thing and as I said every tutorial I'll keep on creating folders and developing our own project over here now let's go ahead and create my second folder and this time this will be apis okay so I'll just go ahead and write something like API okay now with respect to this API as I said whatever we do with this local Lama or app.py right over here I've used open API key here I've have used open source models so we'll try to integrate both of them in the form of routes okay so that we'll be able to create an API so let me quickly go ahead and write over here app. Pui so one will be my app. Pui which will be responsible in creating all the apis the second one will specifically be my client.py now client.py in this specific diagram is just imagine like this one web app or mobile app because we are going to integrate this apis with this mobile app or web app okay so quickly let's do this first of all I will go ahead and start writing the code in app.py before I go ahead uh we have to make sure that we need to update all the requirement. txt almost all the libraries have installed it but I'm going to install more three libraries one is langu fast API and uvon okay since I'm going to create my entire Swagger documentation of API using fast API right so all these three libraries I'll be using it so first of all I will go ahead and install all these libraries that will once we run the code right now let's go ahead and write my app.py code okay now as usual first of all uh let me just open my terminal okay and let me do one thing with respect to the terminal I will go ahead and write pip install pip install minus our requirement. txt okay first of all I need to just write CD dot dot okay then I'll clear the screen and then go ahead and write paper install minus r requirement. txt now here you'll be able to see that my entire installation will start taking place and here uh the other three packages that I have actually written right Lang serve and all that will get particular installed okay now till then installation is basically going on let me go ahead and write my code so I will write from Fast API import fast API okay so this is the first uh first library that I'm going to import along with this I have to also make sure that I create or I import my uh chat prom template so from Lang chain since we are going to create that entire apis in this okay do prompts import chat promp template right so this is done then from Lang chain dot chatore models import chat open AI so this is the next one since I need to make sure that I need to create a chat chat application so that is the reason why I'm using this chat models okay uh this is the next library that I'll be going ahead and importing along with this I'll will also use langu which will be responsible in creating my entire apis right so from Lang serve import add routes okay so through this I will be able to add all the routes over there right whatever routes suppose one route will be that I need to interact with my opening API one one route will be to interact with the Lama 2 and all So based on that I will go ahead and import this next thing is import uon okay uon will be required over here oops okay next is import OS see I can probably enable my GitHub co-pilot and I can probably write the code but I don't think so that will be a better way uh I usually use this AI tool which is called as blackbox uh so that it'll help me to write my code faster and uh you know it also explains about the code so I'll probably create another video about it okay so how to basically use this then one more thing that I really want to import over here is my olama so from langin community. llms llms import o Lama okay so this is done all the libraries that is specifically required by my code uh I have actually written that okay and these are all the things that I will require to create my open a API now this is done now what I'm actually going to do over here is that I'm just going to write os. environment and first of all I will initialize my open AI API key so I will write open aore API uncore key okay and this specifically I will load it from os. getet EnV and then I will go ahead and write open aior API uncore key okay so this is the first thing that we really need to do before I do this I will just go back to my o app.py and I will just initialize this okay load. EnV let me quickly copy this entire thing and paste it over here and I will initialize this load underscore okay so this will actually help me to initialize all my environment variable perfect uh I've also loaded my openi API key now let's start this fast API now in order to create the fast API uh I have to create an app here I've given title langin server version 1.0 and the third information I basically want is the description now after this I can use this app and I can keep on adding my routes okay so what I will do uh addore routes and this routes is basically to add all the routes over there right for so the first time when we are adding this particular routes you have to make sure that I give all all the information like whether I'm going up with my app let's say I go with this chat open API chat open AI open AI okay and the third information that I will probably give is my path so this is my one of my one of my uh route you can just consider this open a route and this is my model that I will specifically be using so this is just one way how you can actually add route okay but let me just add some more things because see at the end of the day when we created our first application we used to combine prompt llm and output parser in this specific way so what we'll do over here is that when we are creating routes we also need to make sure that we add all the routes in such a way that I also integrate my prompt template with it okay so here I'm going to say model is equal to chat open AI chat open Ai and I'm going to initialize this particular model and then let me go ahead and create my other model also see o Lama I will just use my Lama 2 Okay so this model also I need to basically create it or call it okay because I I want to use multiple models so here I'm going to write llm and here AMA and this will basically be my model is equal to llama 2 okay so I'm going to use the Lama 2 model so this is my one model over here this is my another model over here okay now let me go quickly go ahead and create my prompt one so my prompt one will be my chat prompt template chat prom template dot frore template okay and here I'm going to basically give one chat prompt okay let's say one of my interaction one I want to use open a API uh for opening an API let's say I want to create an essay so I'll say write me an essay write me an essay about a specific topic that topic I will be giving it okay about some topic okay some topic okay around with 200 words or with 100 words okay so this is my first prom template okay I'm saying this will be my prom template write me an essay about whatever topic I give with 100 words okay something like this so this let's go ahead and write this this is my first promt template then I will create my second promp template okay this is important just just hear me out okay and this prompt template will be responsible in interacting with my open source model so let me say write me a poem I'll say write me a poem about this specific topic with 100 words so in short this first prom template will be interacting with this model that is chat open API prompt 2 will be interacting with llm model okay whatever llm model I've written over here that is Lama 2 now let me go ahead and add this routes so here I'll say add routes okay and again as usual I will write app now here you see I will be combining prompt or model right model will be chat open API and you know this prompt one is specifically for my chat open API right then I will also give the route path so my path will be something like this okay and this will be my API right so here say let's say I'll write SL essay that basically means this path is responsible in interacting with the open API and this is denoted by slash essay so that API URL that you'll be getting will be ending with slay okay the other route and I can keep on adding any number of routes as you want so another route will be like with prompt 2 okay and here I'm going to basically use my llm and let me just go ahead and write this as/ poem okay/ poem so this is my another route this is my another route okay and finally I've created two apis in short and now here I will write if underscore uncore name underscore uncore is double equal toore uncore maincore uncore right now what we are going to do over here this is the starting of the application I will say uvon do run and here I'm going to use my app comma host will specifically be my Local Host see here I'm giving you the Local Host uh this application you can run it in any server that you want right so that is the saying that is the reason why I'm saying this is the first step towards building that production grade application okay and the port number will be 8,000 perfect so this is done I think uh it looks really really amazing we have written the complete code over here and this is my entire app.py with all the API so that basically means if I see the diagram over here this API spot I've have actually created routes along with prompt template I've created and I've used two apis one is open aai and one is Lama tool two routes I've specifically used now my time is to basically create this web app and mobile app okay and I here I will just try to create a simple web app the reason why I'm creating this simple web app because it will be able to interact with this okay now what I will do let's go ahead and run this and see whether everything is running fine or not okay so here what I will do I will go to my CD which folder this is this is basically my API folder okay so CD API oops Port let me just write it Port okay done CD I'll save this CD API okay and then here I'm going to write python app.py okay now once I execute this from Lang chain uh Lang chain. prompts just let me see the documentation whether it is correct or not it should be prompts okay so a small issue over here it should be prompts now let me just go ahead and execute it now I think it should work fine uh so here you can see import error uh SSE Starlet okay so this is one of the dependency that is probably coming up uh I will quickly go ahead and update my requirement. txt okay and let me do one thing just let me write pip install this particular application okay so I will go and write pip install control V oops pip install and SSC Starlet okay so once this installation will probably happen I think now we'll not get an error now if I write python app.py it should run I guess so it is now running okay uh so let's go ahead and open this Local Host uh now here you can see I'm getting details not found but if you really want to see that entire apis that is basically created you can just write slash docs now here you can see your entire langin server see I've created open aai input schema everything is given essay essay is also there poem is also there and all right so all the apis is almost created see here you can see what is the input what is the output output schema what is is basically required everything is probably given over here and this is basically called as a Swagger UI documentation okay the entire Swagger UI documentation is done now perfect your apis part is basically created now how do we interact with this apis that is the most important part so for that what we are going to basically do I'm going to uh let let let let let let this terminal be hidden over here I'm going to create my client.py okay now with respect to the client.py what we are going to do and let me do one thing till then I will go ahead and disable this extension okay because I don't want this extension to disturb things okay disable perfect I will show you this extension it is a very powerful extension okay now this client. py is my app it can be my app okay so first of all what I'll do I will go ahead and import requests okay after importing request I'm going to write import streamlet as streamlet as St okay so two libraries I'm going to import request and streamlet understand I'm creating a web app I can create a front end that will interact with the API okay so here first of all I will write two definition or two important function one is uh get underscore open aore response and here I'm going to basically go ahead and write my input undor text okay here I will call I will probably call use this request object and create my response now in order to create the response in order to call the API how do I do it so here I'm going to write request. poost and how to basically call it so first of all I need to give the URL understand we are already running this URL right this entire Local Host if you probably see over here everything is running over here right if you if you see this okay if you probably see this and uh try to try to see this entire URL okay you can directly see that in order to call this apis I will be using a URL that is already provided by this particular Swagger UI that is nothing but let's say I want to call the essay UI Ur L okay now in order to call the saay URL which is using the open a API here you can see HTTP Local Host 8,000 sa/ invoke so this is my entire API URL which will be responsible in calling this and here we also know that we need to give one input so what I will do I will go ahead and write over here as Json is equal to and in the form of Json I will give one of my input so input colon okay and here I will write top topic why topic because see here what we are given over here if you see over here topic is there right now this topic will be nothing but whatever input text I am giving to this particular function that same input text will be visible over here okay so this is what we have actually done over here right so input topic colon input un text so this is what is the input I will give and it will hit this particular URL along with this particular input post okay and then finally I get my response now what I will do I will go ahead and take this response convert into a Json and it has a key dictionary value pairs which where my output content will be present inside this variable called as output and one more thing that I require is basically content okay so inside this key my entire response will be available the next thing that I'm actually going to do is similar with the help of O Lama response and here we are going to use Lama 2 so get AMA response input text again request. poost now instead of using this/ essay SL invoke we are going to use SL po/ invoke why/ po/ invoke because SL poem will be responsible in interacting with Lama 2 okay and then I get my Json again I uh I get my response here I'm writing response. Json of output okay so these are my two functions that I've actually created to get the response now what let me do one thing now let me go ahead and create my streamlit framework very simp simple now now from here everything will be simple okay so st. title this this is there I've created two text box one isex input text and one is input text one first text box I'm saying write an essay on whatever topic the second text box I'm writing write a poem of any other topic okay so first one will be interacting with the openi application the second one will be interacting with Lama 2 okay and finally I'm going to call this particular two function that I have created if input. text if I write any text in the first time then it should basically interact with the openi response whatever response I'm getting it will display it over here if input text one I'll just call the AMA response which is interacting with the Llama 2 on this particular URL okay and then I will get the over here the output so this is my entire application which is interacting with the API which is already running over here right now with respect to this client.py what I'm actually going to do I'm going to create another the command prompt and let me run this okay so here I will say uh cond deactivate and I will say cond activate VNV okay and let me just go ahead and run this now see python client.py okay okay sorry it should be streamlet streamlit run client.py okay okay so this is my client side okay file does not exist okay oh I will say CD and I will go to my folder that is API now let me go ahead and write streamlet run client.py now see this this is my Swagger UI the API is running over here and this is my front end application which is basically in now it will interact with this apis okay now if I write the first one the first the first anything in the first text box this is going to interact with the open aipi so I'll say write an aay on machine learning okay so here you can see name get open a response is not defined why this is the eror let's see open AI response oops just a second this function name is does not match and this also AMA response does not match or what okay now I think it should work let's reload it okay now you can see automatically machine learning is a powerful technology that enables computer this this this so the first text box is interacting in the opena IPI write a po poem on machine learning let's say if I give the same thing if I execute it now this is going to interact with the Lama 2 so machine learning is a field of artist that allows computers to make decision or still running sorry uh this was the first response that I got from them uh okay it's running I guess let me reload it write a poem on machine learning okay and I can also write my own custom prompt if I want everybody I was thinking that we could make a bit of interesting by adding some extra challenges so and so so what do you say something something is given okay uh and if I probably see over here with respect to the prompt input text one this is also going over here uh this is my input text okay perfect so everything works fine and here you'll be able to see write a poem about uh this particular topic where with um for a 5 years child okay now let's see I'll just try to change the prompt and see whether it is working fine or not so this has got reloaded it uh let's see whether this is reloaded or not now if I go ahead and reload this write a poem on unicorn okay I'm just writing something unicorn I think it should be able to give the poem Shimmer cod in various colors here are 100 words that describe a unicorn okay something something information is basically coming and this is basically interacting with the entire Lama 2 so I hope uh you've understood this just imagine guys this is already running in the server and this you have the front end now whether it will be a mobile app front end app or Edge device anything you will be able to interact with this entire apis and that is the most amazing thing over here and this is what you go basically to the first phase of the deployment where mainly you create the apis now it's all about using whichever Cloud Server and doing the deployment in set so I hope you like this particular video this was it for my side I'll see you in the next video have a great day thank you and all take care bye-bye\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   \n",
    "Task in this module\n",
    "\n",
    "1. Built a function to find channel_id from youtube channel names.  done\n",
    "2. Select filter method by which we want to select videos from competitors youtube channel (right now its picking latest 5 videos). done \n",
    "3. Compare and validate the results from filtered results. done\n",
    "\n",
    "4. Find accurate model or algorithm to summarize any length of transcription (divide transcriptions into chunks and feed the chunks\n",
    "                                                                             to the model with some overlap between them for context)\n",
    "\n",
    "Will take langchain framework for recursive text splitting and use ether open api key or google gemini model to summarize the transcription \n",
    "\n",
    "5. Also fix the length of summary.\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Getting all the video infomation of our creator and extract transcription for all those videos \n",
    "\n",
    "2. Figure out the databse to store transcriptions / embeddings \n",
    "\n",
    "3. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abit_mod1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
